{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "PwOOdxMbusxy2ENmwGATXM",
     "report_properties": {
      "rowId": "Ij8xLXakhHRBywvSBeWvxM"
     },
     "type": "MD"
    }
   },
   "source": [
    "# 1 - Download the Dataset\n",
    "Download the dataset from the following link:\n",
    "https://data.world/crowdflower/sentiment-analysis-in-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "ec4BwDJFeWLgjtXPE8nyMV",
     "report_properties": {
      "rowId": "9xkHJvyA74xIkf7p0ueXvR"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('text_emotion.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "tqiIATh2bQ0jgvPPDoehq8",
     "report_properties": {
      "rowId": "hTDiFagDiuiKSpHmkhlu0s"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['tweet_id', 'author'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "X67P1b5WoT338E5FFVXQjl",
     "report_properties": {
      "rowId": "rPAMEyLq4LZSMfjqHT4oVf"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "MjpJIgZiKHvNrfEoqGWr0e",
     "report_properties": {
      "rowId": "6E0FfZTW3a1uCOxdKSiLpZ"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends soon!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo we want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends soon!\n",
       "4     neutral  @dannycastillo we want to trade with someone w..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "CYyd6ENGTGrIZ66UzWheMg",
     "report_properties": {
      "rowId": "vzQiBm7ancwjCEpucQnhkx"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['content'])\n",
    "tokens = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  48998\n"
     ]
    }
   ],
   "source": [
    "# Calculate the vocabulary size\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: ', vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text to sequence of integers\n",
    "sequences = tokenizer.texts_to_sequences(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length:  37\n"
     ]
    }
   ],
   "source": [
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "print('Max Sequence Length: ', max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to the same length\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'boredom' 'empty' 'enthusiasm' 'fun' 'happiness' 'hate' 'love'\n",
      " 'neutral' 'relief' 'sadness' 'surprise' 'worry']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "Y = df['sentiment']\n",
    "print(np.unique(Y))\n",
    "num_classes = len(np.unique(Y))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "labels_encoded = le.fit_transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to one-hot encoding\n",
    "Y = to_categorical(labels_encoded, num_classes=num_classes)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   320,   453,   625],\n",
       "       [    0,     0,     0, ...,   488,  3442,     8],\n",
       "       [    0,     0,     0, ...,     1,    55,    50],\n",
       "       ...,\n",
       "       [    0,     0,     0, ..., 40706,   438,   187],\n",
       "       [    0,     0,     0, ...,    32,    24,  2947],\n",
       "       [    0,     0,     0, ...,  2061,  3604,   579]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Define your Recurrent Neural Network\n",
    "Define an RNN with the following layers:\n",
    "\n",
    "The input layer is an embedding layer with the following parameters:\n",
    "the input dimension is the vocabulary size;\n",
    "the output dimension is 10;\n",
    "the input length is the maximum sequence length;\n",
    "\n",
    "Define an LSTM layer with 128 units;\n",
    "\n",
    "Define an LSTM layer with 64 units;\n",
    "\n",
    "Define a fully connected layer with:\n",
    " 100 units;\n",
    " activation function: ReLU;\n",
    "\n",
    "Dropout layer with 0.5 rate;\n",
    "\n",
    "The output layer is a fully-connected layer with:\n",
    "5 units and activation function: softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 37, 10)            489980    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 37, 128)           71168     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               6500      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 13)                1313      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 618,369\n",
      "Trainable params: 618,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input Embedding layer\n",
    "model.add(Embedding(vocabulary_size,10, input_length=max_sequence_length))\n",
    "\n",
    "# Add the LSTM layers\n",
    "model.add(LSTM(128, return_sequences=True))  # Return sequences for the next LSTM layer\n",
    "model.add(LSTM(64))\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add Dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Choosing Hyperparameters\n",
    "\n",
    "Build the network using the following parameters:\n",
    "- Optimizer: Adam\n",
    "- Loss function: categorical_crossentropy\n",
    "- Metrics: accuracy\n",
    "- Batch size: 256\n",
    "- Epochs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Training Network\n",
    "Use Keras to implement the network described and train your data.\n",
    "Classification metrics:\n",
    "Print the accuracy measure on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 16s 126ms/step - loss: 2.2349 - accuracy: 0.2075 - val_loss: 2.1459 - val_accuracy: 0.2183\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 2.1344 - accuracy: 0.2333 - val_loss: 2.0526 - val_accuracy: 0.2579\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 14s 125ms/step - loss: 1.9836 - accuracy: 0.2848 - val_loss: 2.0197 - val_accuracy: 0.3018\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 1.8396 - accuracy: 0.3436 - val_loss: 2.0820 - val_accuracy: 0.3081\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 14s 127ms/step - loss: 1.6939 - accuracy: 0.3884 - val_loss: 2.1776 - val_accuracy: 0.2894\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 1.5237 - accuracy: 0.4585 - val_loss: 2.2593 - val_accuracy: 0.2793\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 1.3356 - accuracy: 0.5368 - val_loss: 2.4411 - val_accuracy: 0.2765\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 1.1740 - accuracy: 0.6070 - val_loss: 2.6041 - val_accuracy: 0.2636\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 15s 133ms/step - loss: 1.0440 - accuracy: 0.6577 - val_loss: 2.8896 - val_accuracy: 0.2498\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 15s 134ms/step - loss: 0.9270 - accuracy: 0.7013 - val_loss: 3.1393 - val_accuracy: 0.2471\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "rnn = model.fit(X_train, Y_train, batch_size=256, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 9ms/step - loss: 3.1393 - accuracy: 0.2471\n",
      "Accuracy on test data: 24.71%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on test data: {:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [
    "Ij8xLXakhHRBywvSBeWvxM",
    "9xkHJvyA74xIkf7p0ueXvR",
    "hTDiFagDiuiKSpHmkhlu0s",
    "rPAMEyLq4LZSMfjqHT4oVf",
    "6E0FfZTW3a1uCOxdKSiLpZ",
    "vzQiBm7ancwjCEpucQnhkx"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
